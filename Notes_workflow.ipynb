{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3a4fa2",
   "metadata": {},
   "source": [
    "## üìÅ Project Setup and Structure\n",
    "\n",
    "### Step 1: Project Template\n",
    "- Start by executing the `template.py` file to create all initial required files and folder.\n",
    "\n",
    "### Step 2: Package Management\n",
    "- Write the setup for importing local packages in `setup.py` and `pyproject.toml` files.\n",
    "- **Tip**: Learn more about these files from `crashcourse.txt`.\n",
    "- install required moduled listed in requirements.txt \n",
    "    - \"pip install -r requirements.txt\"\n",
    "\n",
    "\n",
    "## üìä MongoDB Setup and Data Management\n",
    "\n",
    "### Step 4: MongoDB Atlas Configuration\n",
    "1. Sign up for [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) and create a new project.\n",
    "2. Set up a free M0 cluster, configure the username and password, and go to \"network access\" and ip address(`0.0.0.0/0`) so that you can access it from anywhere and any network.\n",
    "3. Retrieve the MongoDB connection string for Python and save it (replace `<password>` with your password).\n",
    "\n",
    "### Step 5: Pushing Data to MongoDB\n",
    "1. Create a folder named `notebook`, add the dataset, and create a notebook file `mongoDB_demo.ipynb`.\n",
    "2. Use the notebook to push data to the MongoDB database.\n",
    "3. Verify the data in MongoDB Atlas under Database > Browse Collections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e75b85",
   "metadata": {},
   "source": [
    "## **Note**\n",
    "### **-e .**\n",
    "- e in requirements.txt  :  SO basically any directory with file name   __init__.py is a package and since it stored in our local machine so we call it local packages.\n",
    "- so if we wanted to import src anywhere in local machine without errors( when importing src in other directories) then we need to install these local packages in your local machine.\n",
    "\n",
    "- So how to install it in venv : just add -e . in the end of requirements.txt file.\n",
    "- The setup.py and pyproject.toml file works together to install local packages in the venv\n",
    "- so now you can access src package outside the src or anywhere within this venv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2a60b",
   "metadata": {},
   "source": [
    "## **setup.py and pyproject.toml**\n",
    "\n",
    "1. What is a pyproject.toml file?\n",
    "\n",
    "TOML (Tom‚Äôs Obvious, Minimal Language): It‚Äôs a simple configuration file format (like JSON or YAML) but is easier to read and write. \n",
    "TOML is becoming the standard for Python packaging metadata.\n",
    "\n",
    "2. Why pyproject.toml is important:\n",
    "\n",
    "> It was introduced with PEP 518 to modernize Python package building. Previously, everything was done using setup.py \n",
    "  but now pyproject.toml allows for more flexibility, better dependency management, and cleaner project configuration.\n",
    "> It centralizes metadata about the project: project name, version, dependencies, authors, etc.\n",
    "> It supports various build systems (like setuptools, poetry, etc.).\n",
    "\n",
    "3. Explaining sections of pyproject.toml:\n",
    "\n",
    "[project]: Defines the basic project information (name, version, description, authors).\n",
    "[tool.setuptools]: Specifies that setuptools is being used to build the project.\n",
    "[tool.setuptools.dynamic]: Links the external files (like requirements.txt) to dynamically pull dependencies.\n",
    "\n",
    "4. setup.py with the advent of pyproject.toml: Some tasks previously handled by setup.py (like metadata) are now managed \n",
    "   by pyproject.toml. However, setup.py can still be used, especially if you have complex build steps.\n",
    "\n",
    "5. How do setup.py, pyproject.toml, and requirements.txt work together?\n",
    "\n",
    "> pyproject.toml: It‚Äôs now the central place for project metadata. Instead of defining your dependencies and project \n",
    "  information in setup.py, you can define them in pyproject.toml.\n",
    "  As we did in your project, the line [tool.setuptools.dynamic] dependencies = {file = \"requirements.txt\"} links your requirements.txt \n",
    "  file to the TOML file, so when the project is built, the dependencies are fetched from requirements.txt.\n",
    "\n",
    "> setup.py: While it‚Äôs still used for custom builds and configurations, most of the basic functionality (like metadata and dependencies) \n",
    "  is being transferred to pyproject.toml. You might still keep a minimal setup.py if you have custom build steps, but for many projects, \n",
    "  it‚Äôs not necessary anymore with pyproject.toml.\n",
    "\n",
    "> requirements.txt: It lists all project dependencies and their versions.\n",
    "\n",
    "When you run pip install -r requirements.txt, it ensures that all dependencies are installed. The pyproject.toml file can reference \n",
    "it (as we did) so that package dependencies are automatically pulled from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3d30c",
   "metadata": {},
   "source": [
    "# **Data Ingestion üì•**\n",
    "- src.constant\n",
    "    - Add code in constant dir : add all constant variables here.\n",
    "- src.configuration \n",
    "    - Add code to mongo_db_connection.py and define the func for mongo_db connection to stablish connection with mongo db server.\n",
    "    - How to set MongoDb URL in venv variable  for (os.getenv(MONGODB_URL_KEY) in src.configure.mongo_db_connection.py)---> set: export MONGODB_URL=\"mongodb+srv://santosh4thmarch_db_user:santosh@#9605@cluster0.5cjjjrf.mongodb.net/?appName=Cluster0\"\n",
    "    check: echo $MONGODB_URL\n",
    "\n",
    "\n",
    "    - in constants package MONGODB_URL_KEY = \"MONGODB_URL\" must be as same beacause os.getenv(MONGODB_URL_KEY) will look for the str \"MONGODB_URL\" which is saved in venv byt this command        #export MONGODB_URL=\"mongodb+srv://santosh4thmarch_db_user:santosh@#9605@cluster0.5cjjjrf.mongodb.net/?appName=Cluster0\" \n",
    "\n",
    "    - > The real issue is that the MongoDB URL contains @#9605 which needs to be URL-encoded as %40%239605. Update your environment variable with the properly encoded credentials:\n",
    "    - > export MONGODB_URL=\"mongodb+srv://santosh4thmarch_db_user:santosh%40%239605@cluster0.5cjjjrf.mongodb.net/?appName=Cluster0\"\n",
    "\n",
    "\n",
    "- src.data_access\n",
    "    - Add code in proj1_data.py , it will use configuration.mongo_db_connection.py and fetch data from mongoDB and convert it into data frame\n",
    "- src.entity\n",
    "    - Add code to config_entity.py , till DataIngestionConfig class --> pulling variables data from constant local package module ---> and  storing data ingestion variables , we are gonna use dataclass(this Auto creates the essential methods like __init__ so we just need to store varaibles as instance) module to store varibales \n",
    "    - Add code to Artifact_entity.py, till DataIngestionArtifact class : it will return file paths of output data file like training file path\n",
    "\n",
    "- src.components\n",
    "    - Add code in data_ingestion.py , in this file we are gonna use all 4 points that we dicussed in upper and it will save Train & Test data sets in the end.\n",
    "\n",
    "- src.pipeline\n",
    "    - Add code in training_pipeline.py : it will use all files and modules to fetch and save mongo db data into our local for instant.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2654b",
   "metadata": {},
   "source": [
    "# **Data Validation, Data Transformation & Model Trainer**\n",
    "\n",
    "## Data Validation\n",
    "1. complete the work on src.utils.main_utils.py (it have some reusable function which will be used in most of MLops projects), and config.schema.yaml (to store dataset table schema details for data validation) files\n",
    "2. follow below workflow and add code in these\n",
    "    - constants : All varibles and their values for data validation has been added already\n",
    "    - config_entity : create @dataclass class to store data validation related only paths or orther varibles values\n",
    "    - artifact_entity : store what type of values and what Data validation will return in the end.\n",
    "    - components : code src.components.data_validation.py file.\n",
    "    - pipeline : add code for data validation in src.pipeline.training pipeline\n",
    "    - app.py/ demo.py\n",
    "\n",
    "## Data Trasformation\n",
    "### Data tranformation workflow: \n",
    "    - constants : All varibles and their values for data Transformation has been added already\n",
    "    - config_entity : create @dataclass class to store data Transformation related only paths or orther varibles values\n",
    "    - artifact_entity : store what type of values and what Data Transformation will return in the end.\n",
    "    - components : code src.components.Transformation.py file.\n",
    "    - pipeline : add code for data Transformation in src.pipeline.training pipeline\n",
    "    - app.py/ demo.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb6757",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc202c09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2d7fa6e",
   "metadata": {},
   "source": [
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378d022",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2be49300",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ed027d0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
